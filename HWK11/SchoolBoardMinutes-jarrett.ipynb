{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# School Board Minutes\n",
    "\n",
    "Scrape all of the school board minutes from http://www.mineral.k12.nv.us/pages/School_Board_Minutes\n",
    "\n",
    "Save a CSV called `minutes.csv` with the date and the URL to the file. The date should be formatted as YYYY-MM-DD.\n",
    "\n",
    "**Bonus:** Download the PDF files\n",
    "\n",
    "**Bonus 2:** Use [PDF OCR X](https://solutions.weblite.ca/pdfocrx/index.php) on one of the PDF files and see if it can be converted into text successfully.\n",
    "\n",
    "* **Hint:** If you're just looking for links, there are a lot of other links on that page! Can you look at the link to know whether it links or minutes or not? You'll want to use an \"if\" statement.\n",
    "* **Hint:** You could also filter out bad links later on using pandas instead of when scraping\n",
    "* **Hint:** If you get a weird error that you can't really figure out, you can always tell Python to just ignore it using `try` and `except`, like below. Python will try to do the stuff inside of 'try', but if it hits an error it will skip right out.\n",
    "* **Hint:** Remember the codes at http://strftime.org\n",
    "* **Hint:** If you have a date that you've parsed, you can use `.dt.strftime` to turn it into a specially-formatted string. You use the same codes (like %B etc) that you use for converting strings into dates.\n",
    "\n",
    "```python\n",
    "try:\n",
    "  blah blah your code\n",
    "  your code\n",
    "  your code\n",
    "except:\n",
    "  pass\n",
    "```\n",
    "\n",
    "* **Hint:** You can use `.apply` to download each pdf, or you can use one of a thousand other ways. It'd be good `.apply` practice though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set headers and grab HTML\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)' \\\n",
    "    'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "url = \"http://www.mineral.k12.nv.us/pages/School_Board_Minutes\"\n",
    "html = requests.get(url, headers=headers).content\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "rows = soup.find_all('a')\n",
    "\n",
    "for row in rows[:74]:\n",
    "    try:\n",
    "        if re.search('^([/]files[/])', row.get('href')).group(1) == '/files/':\n",
    "            text_date = row.text.strip()\n",
    "            url = row.get('href')\n",
    "            row_dict = {\n",
    "                'text_date': text_date,\n",
    "                'url': url\n",
    "            }\n",
    "            all_rows.append(row_dict)\n",
    "    except:\n",
    "        pass\n",
    "all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['text_date'].str.replace(r\"\\s\\d\\d?,\\s\\d{4}$\", \"\")\n",
    "df['day'] = df['text_date'].str.replace(r\"\\D\", \"\").str[:-4].str.zfill(2)\n",
    "df['year'] = df['text_date'].str.replace(r\"\\D\", \"\").str[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['month'] + df['day'] + df['year'], format='%B%d%Y')\n",
    "del df['month'], df['day'], df['year'], df['text_date']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to CSV\n",
    "df.to_csv('minutes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from CSV\n",
    "df = pd.read_csv('minutes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download files\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_experimental_option('prefs',  {\n",
    "    \"plugins.always_open_pdf_externally\": True\n",
    "})\n",
    "\n",
    "def download_url(url):\n",
    "    url = \"http://www.mineral.k12.nv.us\" + url\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "df['url'].apply(download_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
